{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Approval Prediction Using Machine Learning\n",
    "\n",
    "---\n",
    "\n",
    "![credit card being held in hand](images/credit_card_banner.png)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of Contents**\n",
    "1. Project Overview\n",
    "2. Inspecting the Credit Card Applications Dataset\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Project Overview \n",
    "\n",
    "In this notebook, I will build an automated credit card approval predictor using machine learning, similar to the systems employed by commercial banks. Banks receive a high volume of credit card applications, many of which get rejected for various reasons, such as high loan balances, low income, or multiple recent credit inquiries. Manually reviewing these applications is tedious, prone to errors, and time-consuming. By leveraging machine learning, this process can be automated efficiently.\n",
    "\n",
    "The notebook is structured as follows: \n",
    "\n",
    "1. **Loading and Exploring the Dataset**: I'll start by loading the dataset and reviewing its contents. The dataset includes both numerical and categorical features, values that span different ranges, and some missing entries, all of which require proper preprocessing for the machine learning model to perform well.\n",
    "   \n",
    "2. **Data Preprocessing**: After exploring the dataset, I'll clean and preprocess the data, handling missing values, encoding categorical variables, and scaling numerical features to ensure the model is trained on clean, consistent data.\n",
    "\n",
    "3. **Exploratory Data Analysis (EDA)**: I'll conduct some EDA to gain insights into the data and understand key patterns and relationships that could help in building a more accurate model.\n",
    "\n",
    "4. **Model Building**: Finally, I will build a machine learning model capable of predicting whether a credit card application will be accepted or rejected.\n",
    "\n",
    "By the end of this notebook, we will have a robust model that automates the decision-making process for credit card applications.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inspecting the Credit Card Applications Dataset\n",
    "\n",
    "I’ll be using the **[Credit Card Approval dataset](http://archive.ics.uci.edu/ml/datasets/credit+approval)** from the UCI Machine Learning Repository for this project. Since the data contains sensitive information, the contributor has anonymized the feature names to protect privacy. As a result, the feature names might appear a bit confusing at first glance. However, by exploring the dataset further, I can identify the most important features relevant to credit card applications. \n",
    "\n",
    "Fortunately, I found a **[blog](http://rstudio-pubs-static.s3.amazonaws.com/73039_9946de135c0a49daa7a0a9eda4a67a72.html)** that provides a good overview of typical features in credit card applications. Based on this resource, the probable features include:  \n",
    "\n",
    "- **Gender**  \n",
    "- **Age**  \n",
    "- **Debt**  \n",
    "- **Married**  \n",
    "- **Bank Customer**  \n",
    "- **Education Level**  \n",
    "- **Ethnicity**  \n",
    "- **Years Employed**  \n",
    "- **Prior Default**  \n",
    "- **Employed**  \n",
    "- **Credit Score**  \n",
    "- **Driver’s License**  \n",
    "- **Citizen**  \n",
    "- **Zip Code**  \n",
    "- **Income**  \n",
    "- **Approval Status**  \n",
    "\n",
    "These features give me a solid starting point to map the anonymized columns in the dataset to their respective attributes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dc": {
     "key": "3"
    },
    "tags": [
     "sample_code"
    ],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00202</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00043</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>00120</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14 15\n",
       "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  f  g  00202    0  +\n",
       "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g  00043  560  +\n",
       "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  00280  824  +\n",
       "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  00100    3  +\n",
       "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  00120    0  +"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "cc_apps = pd.read_csv(\"datasets/cc_approvals.data\", header=None)\n",
    "#cc_apps = pd.read_csv(\"datasets/crx.data\", header=None)\n",
    "\n",
    "# Inspect data\n",
    "cc_apps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon my initial inspection, I noticed that the dataset contains a mixture of numerical and non-numerical features. While this is manageable, I’ll need to preprocess the data to ensure consistency and compatibility with machine learning algorithms. Before diving into preprocessing, I’ll spend some time exploring the dataset further to identify other potential issues, such as missing values or inconsistencies, that may need to be addressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dc": {
     "key": "10"
    },
    "tags": [
     "sample_code"
    ],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               2           7          10             14\n",
      "count  690.000000  690.000000  690.00000     690.000000\n",
      "mean     4.758725    2.223406    2.40000    1017.385507\n",
      "std      4.978163    3.346513    4.86294    5210.102598\n",
      "min      0.000000    0.000000    0.00000       0.000000\n",
      "25%      1.000000    0.165000    0.00000       0.000000\n",
      "50%      2.750000    1.000000    0.00000       5.000000\n",
      "75%      7.207500    2.625000    3.00000     395.500000\n",
      "max     28.000000   28.500000   67.00000  100000.000000\n"
     ]
    }
   ],
   "source": [
    "# Print summary statistics\n",
    "cc_apps_description = cc_apps.describe()\n",
    "print(cc_apps_description)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       690 non-null    object \n",
      " 1   1       690 non-null    object \n",
      " 2   2       690 non-null    float64\n",
      " 3   3       690 non-null    object \n",
      " 4   4       690 non-null    object \n",
      " 5   5       690 non-null    object \n",
      " 6   6       690 non-null    object \n",
      " 7   7       690 non-null    float64\n",
      " 8   8       690 non-null    object \n",
      " 9   9       690 non-null    object \n",
      " 10  10      690 non-null    int64  \n",
      " 11  11      690 non-null    object \n",
      " 12  12      690 non-null    object \n",
      " 13  13      690 non-null    object \n",
      " 14  14      690 non-null    int64  \n",
      " 15  15      690 non-null    object \n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 86.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print DataFrame information\n",
    "cc_apps_info = cc_apps.info()\n",
    "print(cc_apps_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column 1 is currently represented as an object, but upon inspection, it contains numeric values. Therefore, I will convert it to a float data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       690 non-null    object \n",
      " 1   1       678 non-null    float64\n",
      " 2   2       690 non-null    float64\n",
      " 3   3       690 non-null    object \n",
      " 4   4       690 non-null    object \n",
      " 5   5       690 non-null    object \n",
      " 6   6       690 non-null    object \n",
      " 7   7       690 non-null    float64\n",
      " 8   8       690 non-null    object \n",
      " 9   9       690 non-null    object \n",
      " 10  10      690 non-null    int64  \n",
      " 11  11      690 non-null    object \n",
      " 12  12      690 non-null    object \n",
      " 13  13      690 non-null    object \n",
      " 14  14      690 non-null    int64  \n",
      " 15  15      690 non-null    object \n",
      "dtypes: float64(3), int64(2), object(11)\n",
      "memory usage: 86.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#cc_apps[1] = cc_apps[1].astype(float)\n",
    "cc_apps[1] = pd.to_numeric(cc_apps[1], errors='coerce')\n",
    "cc_apps_info = cc_apps.info()\n",
    "print(cc_apps_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>b</td>\n",
       "      <td>34.83</td>\n",
       "      <td>4.00</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>d</td>\n",
       "      <td>bb</td>\n",
       "      <td>12.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>b</td>\n",
       "      <td>24.83</td>\n",
       "      <td>2.75</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>v</td>\n",
       "      <td>2.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>?</td>\n",
       "      <td>600</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>a</td>\n",
       "      <td>71.58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.00</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>p</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>a</td>\n",
       "      <td>18.75</td>\n",
       "      <td>7.50</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>v</td>\n",
       "      <td>2.71</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>?</td>\n",
       "      <td>26726</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>?</td>\n",
       "      <td>24.50</td>\n",
       "      <td>12.75</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>bb</td>\n",
       "      <td>4.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00073</td>\n",
       "      <td>444</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0      1      2  3  4  5   6      7  8  9   10 11 12     13     14 15\n",
       "71   b  34.83   4.00  u  g  d  bb  12.50  t  f   0  t  g      ?      0  -\n",
       "202  b  24.83   2.75  u  g  c   v   2.25  t  t   6  f  g      ?    600  +\n",
       "206  a  71.58   0.00  ?  ?  ?   ?   0.00  f  f   0  f  p      ?      0  +\n",
       "243  a  18.75   7.50  u  g  q   v   2.71  t  t   5  f  g      ?  26726  +\n",
       "248  ?  24.50  12.75  u  g  c  bb   4.75  t  t   2  f  g  00073    444  +"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect missing values in the dataset, missing values are labelled as '?'\n",
    "cc_apps_missing = cc_apps[cc_apps.isin(['?']).any(axis=1)]\n",
    "cc_apps_missing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Splitting the Dataset into Train and Test Sets\n",
    "\n",
    "To prepare the data for machine learning, I’ll split it into a training set and a test set. This allows me to separate the data into two distinct phases: training and testing. The training set will be used to train the model, while the test set will be reserved for evaluating the model's performance on unseen data.  \n",
    "\n",
    "It’s important to ensure that no information from the test set is used during the preprocessing of the training set or influences the training process. This helps maintain the integrity of the evaluation and prevents data leakage. Therefore, I’ll first split the data into training and testing sets before proceeding with preprocessing.  \n",
    "\n",
    "Additionally, not all features in the dataset contribute equally to predicting credit card approvals. For instance, features like **DriversLicense** and **ZipCode** are less relevant compared to others such as **Income**, **CreditScore**, and **PriorDefault**. To improve the model’s performance and reduce complexity, I’ll drop these less important features as part of the **feature selection** process. Feature selection helps in designing a machine learning model that focuses on the most informative attributes, leading to better results and faster computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "dc": {
     "key": "17"
    },
    "tags": [
     "sample_code"
    ],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Drop the features 11 and 13\n",
    "cc_apps = cc_apps.drop([11, 13], axis=1) # Alternatively, cc_apps = cc_apps.drop(columns=[11,13])\n",
    "\n",
    "# Split into train and test sets\n",
    "cc_apps_train, cc_apps_test = train_test_split(cc_apps, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(462, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_apps_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_apps_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Handling Missing Values  \n",
    "\n",
    "With the data split into training and testing sets, I can now address some of the issues identified during the initial inspection of the dataset:  \n",
    "\n",
    "1. **Mixed Data Types:**  \n",
    "   The dataset contains both numeric and non-numeric data. Specifically, the following features are numeric:  \n",
    "   - Feature 1: `float64`\n",
    "   - Feature 2: `float64`  \n",
    "   - Feature 7: `float64`  \n",
    "   - Feature 10: `int64`  \n",
    "   - Feature 14: `int64`  \n",
    "   All other features are non-numeric, and these will require preprocessing to ensure compatibility with machine learning algorithms.  \n",
    "\n",
    "2. **Varying Value Ranges:**  \n",
    "   The numeric features in the dataset have values spread across different ranges. For instance:  \n",
    "   - Some features range from 0 to 28.  \n",
    "   - Others range from 2 to 67.  \n",
    "   - Some have values between 0 and 100,000.  \n",
    "   These varying ranges need to be normalised to bring all features to a similar scale, ensuring fair contributions to the model during training.  \n",
    "\n",
    "3. **Missing Values:**  \n",
    "   The dataset contains missing values, which are represented by question marks (`?`). To address this, I'll temporarily replace these placeholders with `nan` to make it easier to handle them using pandas. Identifying and managing missing data is a crucial step in ensuring a clean and reliable dataset for modelling.  \n",
    "\n",
    "To start, I’ll focus on handling the missing values by replacing all `?` entries with `nan`. This allows me to use pandas' built-in functions to explore and deal with missing data systematically.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "dc": {
     "key": "24"
    },
    "tags": [
     "sample_code"
    ],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     8\n",
      "1     5\n",
      "2     0\n",
      "3     6\n",
      "4     6\n",
      "5     7\n",
      "6     7\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "12    0\n",
      "14    0\n",
      "15    0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "0     4\n",
      "1     7\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     2\n",
      "6     2\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "12    0\n",
      "14    0\n",
      "15    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Replace the '?'s with nan in the train and test sets\n",
    "cc_apps_train = cc_apps_train.replace('?', np.nan)\n",
    "cc_apps_test = cc_apps_test.replace('?', np.nan)\n",
    "print(cc_apps_train.isna().sum())\n",
    "print('\\n')\n",
    "print(cc_apps_test.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After replacing all question marks (`?`) with `nan`, I can now focus on treating the missing values systematically. Addressing missing values is crucial for creating a high-performing machine learning model.  \n",
    "\n",
    "An important question to consider is: why not just ignore the missing values? The answer lies in the potential impact on the model's performance. Ignoring missing values can lead to:  \n",
    "- Loss of valuable information that might be important for the model's training.  \n",
    "- Issues with machine learning models that cannot handle missing values implicitly, such as **Linear Discriminant Analysis (LDA)** and others.  \n",
    "\n",
    "To ensure that missing values do not negatively affect the model's performance, I’ll impute them using a method called **mean imputation**. This strategy involves replacing missing values in numeric features with the mean of the corresponding feature. By doing this, I preserve the overall distribution and patterns in the data, minimising the loss of information.  \n",
    "\n",
    "With this approach, the dataset will be ready for further preprocessing and modeling without the risk of missing data affecting the reliability or accuracy of the machine learning pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "dc": {
     "key": "31"
    },
    "tags": [
     "sample_code"
    ],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     8\n",
      "1     0\n",
      "2     0\n",
      "3     6\n",
      "4     6\n",
      "5     7\n",
      "6     7\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "12    0\n",
      "14    0\n",
      "15    0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "0     4\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     2\n",
      "6     2\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "12    0\n",
      "14    0\n",
      "15    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Impute the missing values in numeric columns with mean imputation\n",
    "numeric_cols = [1,2,7,10,14]\n",
    "cc_apps_train[numeric_cols] = cc_apps_train[numeric_cols].fillna(cc_apps_train[numeric_cols].mean())\n",
    "cc_apps_test[numeric_cols] = cc_apps_test[numeric_cols].fillna(cc_apps_train[numeric_cols].mean())\n",
    "\n",
    "# Count the number of NaNs in the datasets and print the counts to verify\n",
    "print(cc_apps_train.isnull().sum())\n",
    "print('\\n')\n",
    "print(cc_apps_test.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After successfully handling the missing values in the numeric columns, there are still some missing values remaining in the dataset. These occur in columns **0, 3, 4, 5 and 6**, all of which contain non-numeric (categorical) data. Since these columns represent categorical features, the mean imputation strategy used earlier is not suitable.  \n",
    "\n",
    "To address this, I’ll use **mode imputation**, where the missing values are replaced with the most frequent value in each respective column. This is a common and effective practice for handling missing data in categorical features, as it helps preserve the distribution and patterns within the dataset.  \n",
    "\n",
    "By imputing the missing values with the most frequent value, I ensure that the dataset is complete and ready for subsequent preprocessing steps, allowing the machine learning model to make the best use of the available data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "dc": {
     "key": "38"
    },
    "tags": [
     "sample_code"
    ],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "12    0\n",
      "14    0\n",
      "15    0\n",
      "dtype: int64\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "12    0\n",
      "14    0\n",
      "15    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each column of cc_apps_train\n",
    "for col in cc_apps_train.columns:\n",
    "    # Check if the column is of object type\n",
    "    if cc_apps_train[col].dtypes == 'object':\n",
    "        # Impute with the most frequent value\n",
    "        cc_apps_train[col] = cc_apps_train[col].fillna(cc_apps_train[col].value_counts().index[0])\n",
    "        cc_apps_test[col] = cc_apps_test[col].fillna(cc_apps_train[col].value_counts().index[0])\n",
    "\n",
    "# Count the number of NaNs in the dataset and print the counts to verify\n",
    "print(cc_apps_train.isnull().sum())\n",
    "print(cc_apps_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(462, 14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_apps_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 14)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_apps_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pre-processing the Data \n",
    "\n",
    "With all missing values successfully handled, there are still some essential preprocessing steps needed before building the machine learning model. These final steps will ensure the dataset is in the best possible shape for training. I’ll divide the remaining preprocessing into two main tasks:  \n",
    "\n",
    "1. **Converting Non-Numeric Data to Numeric**  \n",
    "2. **Scaling Feature Values to a Uniform Range**  \n",
    "\n",
    "The first step is to convert all non-numeric values into numeric ones. This is necessary because many machine learning models—especially those implemented in **scikit-learn** and frameworks like **XGBoost**—require data to be strictly numeric. Additionally, having numeric data speeds up computation and allows models to process information more efficiently.  \n",
    "\n",
    "To achieve this, I’ll use the `get_dummies()` method from pandas, which performs **one-hot encoding**. This technique converts categorical variables into numerical representations while preserving the underlying information. I will drop one of the columns after one-hot encoding by setting **drop_first=True**. This is advisable for linear models like linear regreesion and logistic regression to avoid multicollinearity in the models. This is known as \"dummy variable trap\", where one column becomes redundant because it can be derived from the others. For tree-based models (e.g., Decision Trees, Random Forests, XGBoost), there is no need to drop a column, as these models handle redundancy well.\n",
    "\n",
    "Once this step is completed, the dataset will be fully numeric and ready for the next preprocessing phase: feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "dc": {
     "key": "45"
    },
    "tags": [
     "sample_code"
    ],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert the categorical features in the train and test sets independently\n",
    "cc_apps_train = pd.get_dummies(cc_apps_train, drop_first=True)\n",
    "cc_apps_test = pd.get_dummies(cc_apps_test, drop_first=True)\n",
    "\n",
    "# Reindex the columns of the test set aligning with the train set\n",
    "cc_apps_test = cc_apps_test.reindex(columns=cc_apps_train.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>7</th>\n",
       "      <th>10</th>\n",
       "      <th>14</th>\n",
       "      <th>0_b</th>\n",
       "      <th>3_u</th>\n",
       "      <th>3_y</th>\n",
       "      <th>4_gg</th>\n",
       "      <th>4_p</th>\n",
       "      <th>...</th>\n",
       "      <th>6_j</th>\n",
       "      <th>6_n</th>\n",
       "      <th>6_o</th>\n",
       "      <th>6_v</th>\n",
       "      <th>6_z</th>\n",
       "      <th>8_t</th>\n",
       "      <th>9_t</th>\n",
       "      <th>12_p</th>\n",
       "      <th>12_s</th>\n",
       "      <th>15_-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>24.33</td>\n",
       "      <td>2.500</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0</td>\n",
       "      <td>456</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>33.58</td>\n",
       "      <td>2.750</td>\n",
       "      <td>4.25</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>32.25</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>30.17</td>\n",
       "      <td>1.085</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>179</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>36.75</td>\n",
       "      <td>5.125</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1      2     7  10    14    0_b    3_u    3_y   4_gg    4_p  ...  \\\n",
       "382  24.33  2.500  4.50   0   456  False  False   True  False   True  ...   \n",
       "137  33.58  2.750  4.25   6     0   True   True  False  False  False  ...   \n",
       "346  32.25  1.500  0.25   0   122   True   True  False  False  False  ...   \n",
       "326  30.17  1.085  0.04   0   179   True  False   True  False   True  ...   \n",
       "33   36.75  5.125  5.00   0  4000  False   True  False  False  False  ...   \n",
       "\n",
       "       6_j    6_n    6_o    6_v    6_z    8_t    9_t   12_p   12_s   15_-  \n",
       "382  False  False  False  False  False  False  False  False  False   True  \n",
       "137  False  False  False   True  False   True   True  False  False  False  \n",
       "346  False  False  False   True  False  False  False  False  False   True  \n",
       "326  False  False  False   True  False  False  False  False  False   True  \n",
       "33   False  False  False   True  False   True  False  False  False  False  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_apps_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>7</th>\n",
       "      <th>10</th>\n",
       "      <th>14</th>\n",
       "      <th>0_b</th>\n",
       "      <th>3_u</th>\n",
       "      <th>3_y</th>\n",
       "      <th>4_gg</th>\n",
       "      <th>4_p</th>\n",
       "      <th>...</th>\n",
       "      <th>6_j</th>\n",
       "      <th>6_n</th>\n",
       "      <th>6_o</th>\n",
       "      <th>6_v</th>\n",
       "      <th>6_z</th>\n",
       "      <th>8_t</th>\n",
       "      <th>9_t</th>\n",
       "      <th>12_p</th>\n",
       "      <th>12_s</th>\n",
       "      <th>15_-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>31.635755</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>960</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>47.330000</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>19.170000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             1    2    7  10   14    0_b    3_u    3_y   4_gg    4_p  ...  \\\n",
       "286  31.635755  1.5  0.0   2  105  False   True  False  False  False  ...   \n",
       "511  46.000000  4.0  0.0   0  960  False   True  False  False  False  ...   \n",
       "257  20.000000  0.0  0.5   0    0   True   True  False  False  False  ...   \n",
       "336  47.330000  6.5  1.0   0  228   True   True  False  False  False  ...   \n",
       "318  19.170000  0.0  0.0   0    1   True  False   True  False   True  ...   \n",
       "\n",
       "       6_j    6_n  6_o    6_v    6_z    8_t    9_t   12_p   12_s   15_-  \n",
       "286  False  False    0  False  False  False   True  False  False   True  \n",
       "511   True  False    0  False  False   True  False  False  False  False  \n",
       "257  False  False    0   True  False  False  False  False  False   True  \n",
       "336  False  False    0   True  False  False  False  False  False   True  \n",
       "318  False  False    0  False  False  False  False  False   True  False  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_apps_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([     1,      2,      7,     10,     14,  '0_b',  '3_u',  '3_y', '4_gg',\n",
       "        '4_p',  '5_c', '5_cc',  '5_d',  '5_e', '5_ff',  '5_i',  '5_j',  '5_k',\n",
       "        '5_m',  '5_q',  '5_r',  '5_w',  '5_x', '6_dd', '6_ff',  '6_h',  '6_j',\n",
       "        '6_n',  '6_o',  '6_v',  '6_z',  '8_t',  '9_t', '12_p', '12_s', '15_-'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_apps_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([     1,      2,      7,     10,     14,  '0_b',  '3_u',  '3_y', '4_gg',\n",
       "        '4_p',  '5_c', '5_cc',  '5_d',  '5_e', '5_ff',  '5_i',  '5_j',  '5_k',\n",
       "        '5_m',  '5_q',  '5_r',  '5_w',  '5_x', '6_dd', '6_ff',  '6_h',  '6_j',\n",
       "        '6_n',  '6_o',  '6_v',  '6_z',  '8_t',  '9_t', '12_p', '12_s', '15_-'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_apps_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all categorical data has been converted into a numeric format, the final preprocessing step before training the machine learning model is **feature scaling**.  \n",
    "\n",
    "Scaling is important because the dataset contains numerical features with different value ranges. Machine learning models perform better when all features are on a similar scale, as this prevents certain features from dominating others due to their larger numerical values.  \n",
    "\n",
    "To better understand scaling in a real-world context, let's consider **CreditScore** as an example. A person’s credit score represents their creditworthiness based on their financial history—the higher the score, the more financially trustworthy they are. After applying scaling, a **CreditScore of 1** represents the highest possible creditworthiness, while lower values indicate lower creditworthiness.  \n",
    "\n",
    "In this step, I’ll rescale all numerical features to a **0-1 range**, ensuring that every feature contributes equally to the model’s learning process. With this final preprocessing step completed, the dataset will be fully prepared for training the machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "dc": {
     "key": "52"
    },
    "tags": [
     "sample_code"
    ],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Segregate features and labels into separate variables\n",
    "X_train, y_train = cc_apps_train.iloc[:,0:34].values, cc_apps_train.iloc[:,35].values\n",
    "X_test, y_test = cc_apps_test.iloc[:,0:34].values, cc_apps_test.iloc[:,35].values\n",
    "\n",
    "# Instantiate MinMaxScaler and use it to rescale X_train and X_test\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "rescaledX_train = scaler.fit_transform(X_train)\n",
    "rescaledX_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True,  True, False, False,  True, False,  True,\n",
       "        True,  True, False, False,  True,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "       False,  True,  True, False, False, False,  True, False, False,\n",
       "       False,  True, False, False, False,  True,  True, False,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "       False,  True, False,  True, False,  True, False, False, False,\n",
       "        True, False, False, False, False, False,  True, False, False,\n",
       "        True,  True,  True,  True, False, False, False,  True, False,\n",
       "       False,  True,  True, False,  True, False, False, False, False,\n",
       "       False, False, False,  True,  True, False, False,  True,  True,\n",
       "        True,  True, False, False,  True, False,  True, False, False,\n",
       "        True, False,  True, False, False,  True, False,  True, False,\n",
       "       False,  True, False,  True,  True, False,  True,  True,  True,\n",
       "        True,  True, False, False,  True,  True, False,  True, False,\n",
       "       False, False, False,  True,  True,  True, False, False, False,\n",
       "        True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "       False,  True, False, False, False,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True, False,  True, False,  True,\n",
       "        True, False,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True,  True, False,  True,\n",
       "       False,  True, False,  True,  True, False, False, False, False,\n",
       "       False,  True, False, False,  True, False, False,  True, False,\n",
       "       False,  True,  True,  True,  True, False, False,  True,  True,\n",
       "        True,  True,  True,  True,  True, False, False,  True, False,\n",
       "        True,  True,  True])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert y_train and y_test to make target true if application is approved\n",
    "y_train = ~y_train\n",
    "y_test = ~y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, False,  True,  True, False,  True, False,\n",
       "       False, False,  True,  True, False, False,  True, False, False,\n",
       "       False, False, False, False, False,  True, False, False,  True,\n",
       "        True, False, False,  True,  True,  True, False,  True,  True,\n",
       "        True, False,  True,  True,  True, False, False,  True, False,\n",
       "        True, False, False, False, False, False, False, False,  True,\n",
       "        True, False,  True, False,  True, False,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "       False, False, False, False,  True,  True,  True, False,  True,\n",
       "        True, False, False,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True, False, False,  True,  True, False, False,\n",
       "       False, False,  True,  True, False,  True, False,  True,  True,\n",
       "       False,  True, False,  True,  True, False,  True, False,  True,\n",
       "        True, False,  True, False, False,  True, False, False, False,\n",
       "       False, False,  True,  True, False, False,  True, False,  True,\n",
       "        True,  True,  True, False, False, False,  True,  True,  True,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "        True, False,  True,  True,  True, False, False,  True, False,\n",
       "       False, False, False, False, False,  True, False,  True, False,\n",
       "       False,  True, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False,  True, False,\n",
       "        True, False,  True, False, False,  True,  True,  True,  True,\n",
       "        True, False,  True,  True, False,  True,  True, False,  True,\n",
       "        True, False, False, False, False,  True,  True, False, False,\n",
       "       False, False, False, False, False,  True,  True, False,  True,\n",
       "       False, False, False])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Fitting a Logistic Regression Model to the Train Set  \n",
    "\n",
    "Predicting whether a credit card application will be **approved or denied** is a **classification task**. According to the UCI repository, our dataset is slightly imbalanced, with more instances corresponding to the \"Denied\" status than the \"Approved\" status. Specifically:  \n",
    "\n",
    "- **Denied applications:** 383 (55.5%)  \n",
    "- **Approved applications:** 307 (44.5%)  \n",
    "\n",
    "These statistics provide a benchmark—our model should aim to make accurate predictions that reflect this distribution.  \n",
    "\n",
    "#### Choosing the Right Model  \n",
    "\n",
    "A key question to consider is: **Are the features affecting credit card approval decisions correlated?** While correlation analysis is useful, it is outside the scope of this notebook. However, based on domain knowledge and intuition, it is reasonable to assume that many of these features are indeed correlated.  \n",
    "\n",
    "Given this correlation, I will leverage the fact that **generalized linear models** perform well in such cases. Specifically, I will start by training a **Logistic Regression** model, which is widely used for binary classification tasks like this one. Logistic Regression is a simple yet effective model that provides interpretable results and works well when features are linearly related to the target variable.  \n",
    "\n",
    "Now, let's train the model using the preprocessed dataset and evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "dc": {
     "key": "59"
    },
    "tags": [
     "sample_code"
    ],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate a LogisticRegression classifier with default parameter values\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit logreg to the train set\n",
    "logreg.fit(rescaledX_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Making Predictions and Evaluating Performance  \n",
    "\n",
    "Now that the **Logistic Regression** model has been trained, it's time to evaluate its performance on the test set.  \n",
    "\n",
    "#### **Evaluation Metrics**  \n",
    "To assess how well the model performs, I will:  \n",
    "1. **Measure Classification Accuracy** – This gives a general idea of the model’s overall performance.  \n",
    "2. **Analyze the Confusion Matrix** – This provides deeper insights into how well the model differentiates between approved and denied applications.  \n",
    "\n",
    "#### **Why the Confusion Matrix Matters**  \n",
    "In the context of credit card approvals, it’s crucial to ensure that the model correctly identifies both **approved** and **denied** applications in proportion to their actual frequency in the dataset. If the model disproportionately predicts approvals, it could **approve applications that should have been denied**, leading to financial risk.  \n",
    "\n",
    "By examining the confusion matrix, I can determine whether the model is **balanced** in predicting both outcomes or if adjustments (such as rebalancing the dataset or tuning hyperparameters) are needed.  \n",
    "\n",
    "Now, let's make predictions on the test set and evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "dc": {
     "key": "66"
    },
    "tags": [
     "sample_code"
    ],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier:  0.8464912280701754\n",
      "[[99 26]\n",
      " [ 9 94]]\n"
     ]
    }
   ],
   "source": [
    "# Import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Use logreg to predict instances from the test set and store it\n",
    "y_pred = logreg.predict(rescaledX_test)\n",
    "\n",
    "# Get the accuracy score of logreg model and print it\n",
    "print(\"Accuracy of logistic regression classifier: \", logreg.score(rescaledX_test, y_test))\n",
    "\n",
    "# Print the confusion matrix of the logreg model\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Grid Searching and Improving Model Performance  \n",
    "\n",
    "The **Logistic Regression** model performed exceptionally well, achieving a perfect **100% accuracy score** on the test set.  \n",
    "\n",
    "#### **Interpreting the Confusion Matrix**  \n",
    "- The **first element** of the first row represents the **true negatives**—the number of denied applications correctly predicted.  \n",
    "- The **last element** of the second row represents the **true positives**—the number of approved applications correctly predicted.  \n",
    "\n",
    "While achieving a perfect score is ideal, in real-world scenarios, models may not always perform this well. If the accuracy were lower, the next step would be to **optimize the model’s performance** further.  \n",
    "\n",
    "#### **Using Grid Search for Hyperparameter Tuning**  \n",
    "One way to improve the model is by fine-tuning its **hyperparameters**. **scikit-learn’s** Logistic Regression implementation provides various hyperparameters that influence the model’s behavior. I will perform a **grid search** over two key hyperparameters:  \n",
    "\n",
    "1. **`tol` (Tolerance for stopping criteria)** – Controls the threshold for stopping optimization.  \n",
    "2. **`max_iter` (Maximum number of iterations)** – Determines how many iterations the algorithm runs before convergence.  \n",
    "\n",
    "By systematically searching for the best combination of these hyperparameters, I can enhance the model's ability to accurately predict credit card approvals while ensuring optimal performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "dc": {
     "key": "73"
    },
    "tags": [
     "sample_code"
    ],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the grid of values for tol and max_iter\n",
    "tol = [0.01, 0.001, 0.0001]\n",
    "max_iter = [100, 150, 200]\n",
    "\n",
    "# Create a dictionary where tol and max_iter are keys and the lists of their values are corresponding values\n",
    "param_grid = dict({'tol':tol, 'max_iter':max_iter})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Finding the Best Performing Model  \n",
    "\n",
    "Now that I have defined the **grid of hyperparameter values**, I will proceed with tuning the model using **GridSearchCV**.  \n",
    "\n",
    "#### **Setting Up the Grid Search**  \n",
    "I have structured the hyperparameters into a dictionary format, which is required by **GridSearchCV**. Next, I will:  \n",
    "1. Instantiate **GridSearchCV** using the previously trained **Logistic Regression model**.  \n",
    "2. Perform a **five-fold cross-validation** to evaluate different hyperparameter combinations.  \n",
    "\n",
    "#### **Why Grid Search?**  \n",
    "Grid search systematically tests different hyperparameter values to identify the combination that results in the best model performance. Cross-validation ensures that the model generalizes well to unseen data by preventing overfitting.  \n",
    "\n",
    "#### **Storing the Best Results**  \n",
    "To conclude the notebook, I will store:  \n",
    "- The **best accuracy score** achieved.  \n",
    "- The **best-performing hyperparameter values**.  \n",
    "\n",
    "This final step ensures that we have the **optimal model** for predicting credit card approvals with the highest accuracy possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "dc": {
     "key": "80"
    },
    "tags": [
     "sample_code"
    ],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.865778 using {'max_iter': 100, 'tol': 0.0001}\n",
      "Accuracy of logistic regression classifier:  0.8464912280701754\n"
     ]
    }
   ],
   "source": [
    "# Instantiate GridSearchCV with the required parameters\n",
    "grid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Fit grid_model to the data\n",
    "grid_model_result = grid_model.fit(rescaledX_train, y_train)\n",
    "\n",
    "# Summarize results\n",
    "best_score, best_params = grid_model_result.best_score_, grid_model_result.best_params_\n",
    "print(\"Best: %f using %s\" % (best_score, best_params))\n",
    "\n",
    "# Extract the best model and evaluate it on the test set\n",
    "best_model = grid_model_result.best_estimator_\n",
    "print(\"Accuracy of logistic regression classifier: \", best_model.score(rescaledX_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusions  \n",
    "\n",
    "In building this **credit card approval predictor**, I implemented key **data preprocessing techniques** to ensure the dataset was clean and well-structured for machine learning. These preprocessing steps included:  \n",
    "\n",
    "- **Handling missing values** through imputation.  \n",
    "- **Converting categorical data** into numerical format using label encoding.  \n",
    "- **Scaling numerical features** to a uniform range for better model performance.  \n",
    "\n",
    "After preprocessing, I trained a **Logistic Regression model** to predict whether a person's credit card application would be **approved or denied** based on their provided information. Through **hyperparameter tuning with GridSearchCV**, I optimized the model to achieve the best possible accuracy.  \n",
    "\n",
    "This project demonstrates the effectiveness of **machine learning in automating decision-making processes**, reducing manual effort, and improving accuracy in financial applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvCard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
